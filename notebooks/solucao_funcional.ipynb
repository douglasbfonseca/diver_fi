{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dowload and extract\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime\n",
    "\n",
    "#Transforming data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#loading on DB\n",
    "from unicodedata import normalize\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text\n",
    "from kedro.extras.datasets.pandas import SQLTableDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapter layer\n",
    "def download_zip_file(url, path):\n",
    "    file = requests.get(url)\n",
    "    if file.status_code == requests.codes.OK:\n",
    "        with open(path, \"wb\") as cda_fi:\n",
    "            cda_fi.write(file.content)\n",
    "\n",
    "def zip_extract(path):\n",
    "    file = ZipFile(path, \"r\")\n",
    "    file.extractall(\"data_notebooks\")\n",
    "    file.close()\n",
    "\n",
    "def csv_reader(i:int, encoding:str, year, month):\n",
    "    path = \"data_notebooks/cda_fi_BLC_\" + str(i) + \"_\" + year + month + \".csv\"\n",
    "    df = pd.read_csv(path, encoding = encoding, sep = \";\")\n",
    "    return df\n",
    "\n",
    "def write_df_to_db(df, table_name, credentials):\n",
    "    data_set = SQLTableDataSet(table_name=table_name,\n",
    "                               credentials=credentials)\n",
    "\n",
    "    data_set.save(df)\n",
    "    reloaded = data_set.load()\n",
    "\n",
    "def normalizador(elemento):\n",
    "    elemento = normalize('NFKD', elemento).encode('ASCII','ignore').decode('ASCII').lower()\n",
    "    elemento = elemento.replace(\":\",\"_\")\n",
    "    elemento = elemento.replace(\"/\",\"_\")\n",
    "    return elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application layer\n",
    "def extract(url, zip_file_path, encoding, year, month):\n",
    "    \"\"\"\n",
    "    Extrai os dados da fonte\n",
    "    \"\"\"\n",
    "    download_zip_file(url, zip_file_path)\n",
    "    zip_extract(zip_file_path)\n",
    "    df_all = pd.concat([csv_reader(i, encoding, year, month) for i in range(1,9)], ignore_index=True) #Arquivo agregado!\n",
    "    return df_all\n",
    "\n",
    "def transform(df_all):\n",
    "    \"\"\"\n",
    "    Transforma os dados\n",
    "    \"\"\"\n",
    "    # Pegando cnpj e denominação social\n",
    "    df_cnpj = df_all.groupby(by=[\"CNPJ_FUNDO\", \"DENOM_SOCIAL\"]).aggregate(\"sum\").reset_index()[[\"CNPJ_FUNDO\", \"DENOM_SOCIAL\"]]\n",
    "\n",
    "    # Calculando percentual de ativos nos fundos e tirando colunas indesejáveis\n",
    "    vl_fundo = pd.DataFrame(df_all.groupby(by=\"CNPJ_FUNDO\").aggregate(\"sum\")[\"VL_MERC_POS_FINAL\"]).reset_index()\n",
    "    df_all = pd.merge(df_all, vl_fundo, how = 'inner', on = 'CNPJ_FUNDO')\n",
    "    df_all[\"PERCENTUAL_ATIVO\"] = df_all[\"VL_MERC_POS_FINAL_x\"]/df_all[\"VL_MERC_POS_FINAL_y\"]\n",
    "    df_all = df_all[[\"CNPJ_FUNDO\",\"TP_ATIVO\",\"VL_MERC_POS_FINAL_x\", \"VL_MERC_POS_FINAL_y\",\"PERCENTUAL_ATIVO\"]]\n",
    "    df_all.columns = [\"CNPJ_FUNDO\",\"TP_ATIVO\",\"VL_MERC_POS_FINAL\", \"VL_MERC_FUNDO\",\"PERCENTUAL_ATIVO\"]\n",
    "    df_all = df_all.groupby(by=[\"CNPJ_FUNDO\", \"TP_ATIVO\"]).aggregate(\"sum\").reset_index()\n",
    "    df_all = df_all.drop(columns=[\"VL_MERC_POS_FINAL\", \"VL_MERC_FUNDO\"])\n",
    "\n",
    "    #Separando df com os percentuais\n",
    "    df_percentual = df_all.copy()\n",
    "\n",
    "    #Pivotada a fim de conseguir o dataframe no formato ONEHOTENCODER\n",
    "    df_one_hot= pd.pivot_table(df_all, index = [\"CNPJ_FUNDO\"], columns = [\"TP_ATIVO\"], values = \"PERCENTUAL_ATIVO\").reset_index().fillna(0)\n",
    "\n",
    "    return df_cnpj , df_percentual, df_one_hot\n",
    "\n",
    "def load(df_cnpj, df_percentual, df_one_hot, table_cnpj, table_percentual, table_one_hot, credentials):\n",
    "    \"\"\"\n",
    "    Carrega os dataframes no banco de dados PostgreSQL\n",
    "    \"\"\"\n",
    "    df_cnpj.columns = [\"id_cnpj\", \"denom_social\"]\n",
    "    df_percentual.columns = [\"id_cnpj\", \"nome_ativo\", \"percentual_ativo\"]\n",
    "    df_one_hot.columns = [normalizador(elemento) for elemento in df_one_hot.columns.to_list()]\n",
    "    df_one_hot = df_one_hot.rename(columns={'cnpj_fundo': 'id_cnpj'})\n",
    "    write_df_to_db(df_cnpj, table_cnpj, credentials)\n",
    "    write_df_to_db(df_percentual, table_percentual, credentials)\n",
    "    write_df_to_db(df_one_hot, table_one_hot, credentials)\n",
    "\n",
    "def etl_report(url, zip_file_path, encoding_csv, year, month, table_cnpj, table_percentual, table_one_hot, credentials):\n",
    "    df_all = extract(url, zip_file_path, encoding_csv, year, month)\n",
    "    df_cnpj , df_percentual, df_one_hot = transform(df_all)\n",
    "    load(df_cnpj, df_percentual, df_one_hot, table_cnpj, table_percentual, table_one_hot, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal\n",
    "    \"\"\"\n",
    "\n",
    "    #Constantes/Parâmetros\n",
    "    #Conexão CMV\n",
    "    encoding_csv = \"ISO-8859-1\"\n",
    "    month = \"12\"\n",
    "    year = \"2022\"\n",
    "    url = \"https://dados.cvm.gov.br/dados/FI/DOC/CDA/DADOS/cda_fi_\" + year + month + \".zip\"\n",
    "    zip_file_path = \"data_notebooks/cda_fi_\"  + year + month + \".zip\"\n",
    "    #Banco de Dados SQL\n",
    "    credentials = {\"con\": \"postgresql://postgres:senha123@localhost/db_teste_2\"}\n",
    "    table_cnpj = \"tb_cnpj_fundos\"\n",
    "    table_percentual = \"tb_percentual\"\n",
    "    table_one_hot = \"tb_one_hot\"\n",
    "\n",
    "    #Run\n",
    "    etl_report(url, zip_file_path, encoding_csv, year, month, table_cnpj, table_percentual, table_one_hot, credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dougl\\AppData\\Local\\Temp\\ipykernel_17540\\2659767822.py:15: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, encoding = encoding, sep = \";\")\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "630c448730cf9e222e4a43a1739aab5a1cadd6fd314cabf09c8deefa5ee248aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
